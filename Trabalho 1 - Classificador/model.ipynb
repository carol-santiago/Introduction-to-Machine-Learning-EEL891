{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Trabalho 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os DataFrames de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('Dataset/conjunto_de_treinamento.csv')\n",
    "df_train.drop(columns=['id_solicitante'], inplace=True)\n",
    "\n",
    "df_test = pd.read_csv('Dataset/conjunto_de_teste.csv')\n",
    "df_test.drop(columns=['id_solicitante'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo features que atrapalham o resultado final (olhar seção de [Análise de Dados](#análise-dos-dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['valor_patrimonio_pessoal', 'renda_mensal_regular', 'renda_extra', 'meses_no_trabalho','grau_instrucao_companheiro', 'profissao_companheiro', 'estado_onde_trabalha', 'produto_solicitado', 'possui_outros_cartoes', 'possui_telefone_celular', 'grau_instrucao'], inplace=True)\n",
    "df_test.drop(columns=['valor_patrimonio_pessoal', 'renda_mensal_regular', 'renda_extra', 'meses_no_trabalho','grau_instrucao_companheiro', 'profissao_companheiro', 'estado_onde_trabalha', 'produto_solicitado', 'possui_outros_cartoes', 'possui_telefone_celular', 'grau_instrucao'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribuindo valores numéricos a variáveis nominais\n",
    "### Variáveis binárias: \n",
    "- Sim: 1, Não: 0\n",
    "- Sexo - Feminino: 1, Masculino: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_binarias(df):\n",
    "    # Variáveis de sim ou não\n",
    "    yn_cols = ['possui_telefone_residencial', 'vinculo_formal_com_empresa', 'possui_telefone_trabalho']\n",
    "\n",
    "    for col in yn_cols:\n",
    "        df[col] = df[col].map({'N': 0, 'Y': 1})\n",
    "\n",
    "    df['sexo'] = df['sexo'].map({'M': 0, 'F': 1, 'N': None})\n",
    "    df['forma_envio_solicitacao'] = df['forma_envio_solicitacao'].map({'internet': 0, 'correio': 1, 'presencial': 2})\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = var_binarias(df_train)\n",
    "df_test = var_binarias(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatação das variáveis de UF (estados)\n",
    "- Atribui um valor de 0 a 26 para cada sigla. \n",
    "- Ex. 'RJ': 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estados_format(df, column):\n",
    "    # Variáveis de UF\n",
    "    return df[column].map({'AC': 0, 'AL': 1, 'AM': 2, 'AP': 3, 'BA': 4, 'CE': 5, 'DF': 6, 'ES': 7, 'GO': 8, 'MA': 9, 'MG': 10, 'MS': 11, 'MT': 12, 'PA': 13, 'PB': 14, 'PE': 15, 'PI': 16, 'PR': 17, 'RJ': 18, 'RN': 19, 'RO': 20, 'RR': 21, 'RS': 22, 'SC': 23, 'SE': 24, 'SP': 25, 'TO': 26})\n",
    "    \n",
    "df_train['estado_onde_nasceu'] = estados_format(df_train, 'estado_onde_nasceu')\n",
    "df_train['estado_onde_reside'] = estados_format(df_train, 'estado_onde_reside')\n",
    "\n",
    "df_test['estado_onde_nasceu'] = estados_format(df_test, 'estado_onde_nasceu')\n",
    "df_test['estado_onde_reside'] = estados_format(df_test, 'estado_onde_reside')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforma tipos 'str' em 'int'\n",
    "- Algumas colunas estão preenchidas por valores numéricos, porém em formato de 'string'. \n",
    "- A célula a seguir transforma esses valores em 'int'.\n",
    "- Para colunas que possuem valores NaN, a função os transforma em \"-1\" (decisão arbitrária) antes de passar para int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tel_format(df, column):\n",
    "    df[column].replace(' ', -1, inplace=True)\n",
    "    return df[column].map(int)\n",
    "\n",
    "df_train['codigo_area_telefone_trabalho'] = tel_format(df_train, 'codigo_area_telefone_trabalho')\n",
    "df_train['codigo_area_telefone_residencial'] = tel_format(df_train, 'codigo_area_telefone_residencial')\n",
    "\n",
    "df_test['codigo_area_telefone_trabalho'] = tel_format(df_test, 'codigo_area_telefone_trabalho')\n",
    "df_test['codigo_area_telefone_residencial'] = tel_format(df_test, 'codigo_area_telefone_residencial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completando colunas com valores faltando (null)\n",
    "- As colunas nominais que restaram são preenchidas com '-1' em espaços em branco. \n",
    "- Algumas colunas, como 'grau_instrucao_companheiro', foram excluídas simplesmente por possuir uma grande quantidade de valores faltando (>10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train.columns)):\n",
    "    if df_train[df_train.columns[i]].isnull().sum() > 0:\n",
    "        print(df_train.columns[i], df_train[df_train.columns[i]].isnull().sum())\n",
    "        df_train[df_train.columns[i]].fillna(df_train[df_train.columns[i]].mean(), inplace=True)\n",
    "\n",
    "\n",
    "for i in range(len(df_test.columns)):\n",
    "    if df_test[df_test.columns[i]].isnull().sum() > 0:\n",
    "        print(df_test.columns[i], df_test[df_test.columns[i]].isnull().sum())\n",
    "        df_test[df_test.columns[i]].fillna(df_test[df_test.columns[i]].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "\n",
    "#### Para o df_train:\n",
    "- sexo 32\n",
    "- estado_onde_nasceu 822\n",
    "- tipo_residencia 536\n",
    "- meses_na_residencia 1450\n",
    "- profissao 3097\n",
    "- ocupacao 2978\n",
    "- profissao_companheiro 11514\n",
    "- grau_instrucao_companheiro 12860\n",
    "\n",
    "#### Para o df_teste:\n",
    "- sexo 8\n",
    "- estado_onde_nasceu 210\n",
    "- tipo_residencia 125\n",
    "- meses_na_residencia 362\n",
    "- profissao 762\n",
    "- ocupacao 690\n",
    "- profissao_companheiro 2887\n",
    "- grau_instrucao_companheiro 3210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo com Naive Bayes\n",
    "### Introdução ao Naive Bayes\n",
    "\n",
    "O algoritmo Naive Bayes é um método de aprendizado de máquina baseado na aplicação do teorema de Bayes, com a suposição ingênua (daí o nome \"Naive\") de independência condicional entre as características. É amplamente utilizado para problemas de classificação, especialmente quando temos dados categóricos ou discretos.\n",
    "\n",
    "### Separação dos Dados\n",
    "\n",
    "Antes de treinar o modelo, realizamos a preparação dos dados, que envolve a separação do conjunto de treinamento e teste. Os dados são divididos em duas partes: a matriz de características (X_train e X_test), que contém as variáveis independentes, e o vetor de variável alvo (y_train), que contém as classes ou valores a serem previstos.\n",
    "\n",
    "### Treinamento\n",
    "\n",
    "Para criar o modelo Naive Bayes, importamos a classe `GaussianNB` do módulo `sklearn.naive_bayes`. Em seguida, criamos uma instância do modelo chamada `model` usando `GaussianNB()`.\n",
    "\n",
    "A seguir, o modelo é treinado com os dados de treinamento através do método `fit(X_train, y_train)`. O modelo usa os dados de treinamento para aprender as probabilidades das classes e a distribuição dos recursos para fazer previsões.\n",
    "\n",
    "### Previsões\n",
    "\n",
    "Uma vez que o modelo está treinado, realizamos as previsões em um conjunto de teste (`X_test`) usando o método `predict(X_test)`. As previsões resultantes são armazenadas na variável `y_pred` e `predictions`, que será utilizada posteriormente, na seção [Resultados](#resultados).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Separar os dados em treino e teste\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "X_test = df_test.iloc[:, :]\n",
    "\n",
    "# Criar o modelo Naive Bayes\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos Dados\n",
    "\n",
    "Nesta seção, apresentamos duas funções que auxiliaram na análise dos dados antes do treinamento do modelo de Naive Bayes.\n",
    "\n",
    "### Função compare_feature_impact\n",
    "\n",
    "A função `compare_feature_impact(df, target_column)` é responsável por avaliar o \"impacto\" de cada feature (variável) nos resultados do modelo Naive Bayes. Primeiramente, o modelo Naive Bayes é treinado de forma `isolada` (dentro da função) com todas as features do conjunto de treino e sua acurácia é calculada no conjunto de teste como uma linha de base. Em seguida, a função itera sobre cada feature, treina o modelo sem ela e calcula a nova acurácia. A diferença entre a acurácia do modelo completo e a acurácia sem a feature é armazenada em um dicionário chamado `feature_impact`.\n",
    "\n",
    "Além disso, a função cria uma lista chamada `features_to_remove` para armazenar as features cuja remoção resulta em uma diminuição significativa da acurácia (diferença menor ou igual a -0.005). A lista é classificada com base nas diferenças de acurácia para fornecer uma indicação das features que podem ser menos relevantes.\n",
    "\n",
    "Por fim, a função gera um gráfico de barras para visualizar o impacto de cada feature na acurácia do modelo e imprime a lista de features a serem removidas.\n",
    "\n",
    "\n",
    "O método mais utilizado para o treinamento eficiente do modelo foi a análise dos gráficos gerados pelas funções dessa seção, e a partir disso decidir quais features estavam atrapalhando o resultado final. \n",
    "\n",
    "Para a realização dessas decisões, a função `compare_feature_impact` foi utilizada para gerar um gráfico baseado no DataFrame de treinamento com todas as suas features originais. Foi observado (Figura) que a feature 'valor_patrimonio_pessoal' era a principal em termos de desvio da acuracia, e portanto foi a primeira a ser removida. A acurácia medida utilizando todas as features e 20% dos dados do DataFrame de treino como dados de teste foi de 49,3%.\n",
    "\n",
    "![Gráfico com todas as features originais](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\features-originais.png)\n",
    "\n",
    "Após a remoção de 'valor_patrimonio_pessoal', a acurácia subiu para 51.05% e a função `compare_feature_impact` sugeriu a remoção das features 'renda_mensal_regular' e 'renda_extra'. O parâmetro de diferença de acurácias menor ou igual a -0.005 provou ser muito eficiente pois, a cada remoção, o gráfico aparentava se estabilizar ainda mais. A figura abaixo apresenta o gráfico depois da remoção das categorias de renda.\n",
    "\n",
    "![Gráfico sem 'renda_mensal_regular' e 'renda_extra'](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\remocao_de_rendas.png)\n",
    "\n",
    "Com isso, torna-se óbvia a necessidade da remoção de 'meses_no_trabalho'. A nova acurácia sobe para 56.25%, mas ainda variando entre 54.9% até 57.7%. A seguir, o gráfico de impacto após esse passo.\n",
    "\n",
    "![Gráfico sem 'meses_no_trabalho'](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\remocao-meses-trab.png)\n",
    "\n",
    "Seguindo com a análise, a função sugere a remoção de 5 features, mas foi decidido que seriam removidas apenas as duas com diferença de acurácia de maiores módulos. Nesse caso, foram as categorias 'produto_solicitado' e 'estado_onde_trabalha'. A acurácia subiu para uma média de 56.5%, e o gráfico apresentou extrema estabilização entre as variáveis.\n",
    "\n",
    "![Gráfico sem 'produto_solicitado' e 'estado_onde_trabalha'](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\produtosol-estadotrab.png)\n",
    "\n",
    "### Função generate_bar_charts\n",
    "\n",
    "A função `generate_bar_charts(df)` é responsável por gerar gráficos de barras para todas as colunas do DataFrame fornecido. Ela itera sobre cada coluna e verifica o tipo de dados. Se a coluna for do tipo categórico, a função conta o número de ocorrências de cada valor na coluna e cria um gráfico de barras para visualizar a distribuição dos dados.\n",
    "\n",
    "O dicionário `bar_charts` é criado para armazenar os gráficos de barras de cada coluna. Cada gráfico é plotado usando a biblioteca `matplotlib.pyplot`.\n",
    "\n",
    "A segunda etapa do Pré-Processamento de Dados consiste na análise dos gráficos gerados, para avaliar se todas as variáveis estão de acordo com o modelo. Foi notado que as variáveis 'possui_outros_cartoes', 'possui_telefone_celular' e 'grau_instrucao' deveriam ser removidas.\n",
    "\n",
    "![Gráfico de 'grau_instrucao'](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\grauinstrucao.png)\n",
    "\n",
    "![Gráfico de 'possui_telefone_celular'](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\telefonecelular.png)\n",
    "\n",
    "![Gráfico de 'possui_outros_cartoes'](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\possuioutroscartoes.png)\n",
    "\n",
    "Após essa etapa, foi observa uma acurácia média de 56.67% e um gráfico de impacto das variaveis no seguinte formato, sem muitas mudanças:\n",
    "\n",
    "![Gráfico de impacto](C:\\Users\\carol\\OneDrive\\Documentos\\GitHub\\Introduction-to-Machine-Learning-EEL891\\Trabalho 1 - Classificador\\Data Analysis\\graficofuncao2.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def compare_feature_impact(df, target_column):\n",
    "    # Prepare the feature matrix (X) and target variable (y)\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the Naive Bayes model with all features\n",
    "    naive_bayes_model_with_all_features = GaussianNB()\n",
    "    naive_bayes_model_with_all_features.fit(X_train, y_train)\n",
    "\n",
    "    # Get the baseline accuracy with all features included\n",
    "    y_pred_with_all_features = naive_bayes_model_with_all_features.predict(X_test)\n",
    "    baseline_accuracy = accuracy_score(y_test, y_pred_with_all_features)\n",
    "\n",
    "    # Create a dictionary to store the feature names and their corresponding accuracy differences\n",
    "    feature_impact = {}\n",
    "\n",
    "    # Create an empty list to store features with a small accuracy difference\n",
    "    features_to_remove = []\n",
    "\n",
    "    # Iterate over each feature and compare the model performance with and without the feature\n",
    "    for feature in X.columns:\n",
    "        # Train the Naive Bayes model without the current feature\n",
    "        X_train_without_feature = X_train.drop(feature, axis=1)\n",
    "        X_test_without_feature = X_test.drop(feature, axis=1)\n",
    "\n",
    "        naive_bayes_model_without_feature = GaussianNB()\n",
    "        naive_bayes_model_without_feature.fit(X_train_without_feature, y_train)\n",
    "\n",
    "        # Get the accuracy without the feature\n",
    "        y_pred_without_feature = naive_bayes_model_without_feature.predict(X_test_without_feature)\n",
    "        accuracy_without_feature = accuracy_score(y_test, y_pred_without_feature)\n",
    "\n",
    "        # Calculate the accuracy difference compared to the baseline\n",
    "        feature_impact[feature] = baseline_accuracy - accuracy_without_feature\n",
    "\n",
    "        # Check if the accuracy difference is smaller than -0.005 and add the feature to the list\n",
    "        if feature_impact[feature] <= -0.005:\n",
    "            features_to_remove.append(feature)\n",
    "    features_to_remove.sort(key=lambda x: feature_impact[x])    \n",
    "\n",
    "\n",
    "    # Create a bar plot showing the impact of each feature on the model's performance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(feature_impact.keys(), feature_impact.values())\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Accuracy Difference')\n",
    "    plt.title('Impact of Features on Naive Bayes Model Performance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Print the list of features with accuracy difference smaller than -0.005\n",
    "    print(\"Features to Remove:\")\n",
    "    print(features_to_remove)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compare_feature_impact(df_train, 'inadimplente')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_bar_charts(df):\n",
    "    # Cria um dicionário para armazenar os gráficos de barras de cada coluna\n",
    "    bar_charts = {}\n",
    "\n",
    "    # Itera sobre todas as colunas do DataFrame\n",
    "    for column in df.columns:\n",
    "        # Verifica o tipo da coluna (objeto é tratado como categórico)\n",
    "        \n",
    "        # Conta o número de ocorrências de cada valor na coluna\n",
    "        value_counts = df[column].value_counts()\n",
    "\n",
    "        # Cria um gráfico de barras\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.bar(value_counts.index, value_counts.values)\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Quantidade de Ocorrências')\n",
    "        plt.title(f'Contagem de Ocorrências para a Coluna \"{column}\"')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "        # Adiciona o gráfico ao dicionário\n",
    "        bar_charts[column] = plt\n",
    "\n",
    "    return bar_charts\n",
    "\n",
    "generate_bar_charts(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Seção utilizada para salvar os resultados num arquivo \"predictions.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Dataset/conjunto_de_teste.csv')\n",
    "\n",
    "prediction_file = pd.DataFrame(predictions, columns=['inadimplente'])\n",
    "prediction_file = pd.concat([df_test['id_solicitante'], prediction_file], axis=1)\n",
    "prediction_file = prediction_file.to_csv('results/predictions.csv', index=False)\n",
    "\n",
    "\n",
    "prediction_file = pd.read_csv('results/predictions.csv')\n",
    "prediction_file.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabalho-um",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
